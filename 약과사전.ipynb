{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k984530/-url/blob/main/%EC%95%BD%EA%B3%BC%EC%82%AC%EC%A0%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**환경설정**"
      ],
      "metadata": {
        "id": "lPqWWC3VuY81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhgbVvms_vnT",
        "outputId": "877f8579-eb2d-45d1-ed60-69a44c17fd2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision\n",
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install imgaug\n",
        "!pip install PIL\n",
        "!pip install tqdm\n",
        "!pip install codecs\n",
        "!pip install json\n",
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "2-gXpE3drUlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install PIL error 해결 방안\n",
        "!pip install Pillow"
      ],
      "metadata": {
        "id": "RuPpxsK3fspX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# 학습한 파라미터가 저장된 파일 경로\n",
        "trained_params_path = '/content/drive/MyDrive/data/pill_resnet152_dataclass01_aug0.pt'\n",
        "\n",
        "# 사전 학습된 ResNet-152 모델 아키텍처 가져오기\n",
        "resnet152 = models.resnet152(pretrained=True)\n",
        "\n",
        "# 학습한 파라미터 로드\n",
        "trained_params = torch.load(trained_params_path)\n",
        "resnet152.load_state_dict(trained_params)\n",
        "\n",
        "# 이미지에 모델 적용 및 예측 수행\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "# 이미지 전처리를 위한 변환 정의\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 이미지 불러오기 및 전처리\n",
        "image_path = 'path_to_your_image.jpg'\n",
        "image = Image.open(image_path)\n",
        "input_tensor = preprocess(image)\n",
        "input_batch = input_tensor.unsqueeze(0)  # 모델에 들어갈 배치 차원 추가\n",
        "\n",
        "# 모델에 이미지 전달하여 예측 수행\n",
        "resnet152.eval()  # 모델을 평가 모드로 설정\n",
        "with torch.no_grad():\n",
        "    output = resnet152(input_batch)\n",
        "\n",
        "# 예측 결과 출력\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "vMY_WpcgC02e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **copy_crop_pill_from_org.py**"
      ],
      "metadata": {
        "id": "RBKlWutuLdn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "list_dir_pill_org = [\n",
        "    # r'G:\\경구약제 DB\\0.단일 경구약제 1000종\\경구약제 1000종 추가 DB',\n",
        "    # r'G:\\경구약제 DB\\0.단일 경구약제 1000종\\경구약제 1000종 추가 DB_1',\n",
        "    r'G:\\경구약제 DB\\0.단일 경구약제 1000종\\경구약제 1000종 추가 DB_2',\n",
        "]\n",
        "\n",
        "\n",
        "# JSON 파일과 이미지 파일을 읽어서, 이미지를 자르고, 새로운 크기로 resize 후, 새로운 경로에 저장\n",
        "def copy_crop_pill_from_json(args, pathfile_src_json, pathfile_src_png, pathfile_dest_json, pathfile_dest_png):\n",
        "\n",
        "    # 이미지 파일이 없으면 함수를 종료\n",
        "    if not pathfile_src_png.exists() :\n",
        "        args.logger.info(f\"file does'nt exist : {str(pathfile_src_png)}\")\n",
        "        return\n",
        "\n",
        "    # JSON 파일을 새로운 경로에 복사\n",
        "    shutil.copyfile(str(pathfile_src_json), str(pathfile_dest_json))\n",
        "\n",
        "    # crop\n",
        "    dict_pill_info = utils.read_dict_from_json(str(pathfile_src_json))\n",
        "    bbox = dict_pill_info['annotations'][0]['bbox']\n",
        "    np_bbox = np.array([[bbox[0], bbox[1]], [bbox[0] + bbox[2], bbox[1] + bbox[3]]])\n",
        "    np_center = np.average(np_bbox, axis=0)\n",
        "    diff =  np.max(np_bbox[1] - np_bbox[0])\n",
        "    np_low = np_center - diff/2\n",
        "    np_high = np_center + diff/2\n",
        "    np_high = np_high.astype(np.int32)\n",
        "    np_low = np_low.astype(np.int32)\n",
        "\n",
        "    image_cv = utils.open_opencv_file(str(pathfile_src_png))\n",
        "    image_cv_cropped = image_cv[np_low[1]:np_high[1], np_low[0]:np_high[0]]\n",
        "    image_cv_resized = cv2.resize(image_cv_cropped, (args.size_image, args.size_image))\n",
        "\n",
        "    utils.save_opencv_file(image_cv_resized, str(pathfile_dest_png))\n",
        "\n",
        "# 경로 list_dir_pill_org 에 있는 모든 약제 이미지를 처리\n",
        "def copy_crop_pill_from_org(args):\n",
        "    '''\n",
        "    list_dir_pill_org 의 directory은  알약  dir들을 여러 개 포함하고,\n",
        "    알약 dir에는 조건에 따라, 1200여개의 png가 있다.\n",
        "    이를  아래 pathdir_dest dir에 모든다.\n",
        "    단 이미지를 bbox기준으로, 224x224으로 crop한다.\n",
        "    :param args:\n",
        "    :return:\n",
        "    '''\n",
        "    # 새로운 이미지를 저장할 경로\n",
        "    pathdir_dest = Path(r'G:\\proj_pill_data\\pill_data_croped')\n",
        "\n",
        "    for dir_pill_org in list_dir_pill_org :\n",
        "        list_count = [ 1 for _ in Path(dir_pill_org).iterdir()]\n",
        "        count_dir = len(list_count)\n",
        "        index_dir = 0\n",
        "        for pathdir_pill_class_json in Path(dir_pill_org).iterdir():\n",
        "            print(f'working dir index is { index_dir}/{count_dir}, {str(pathdir_pill_class_json)}')\n",
        "            index_dir += 1\n",
        "            if not 'json' in pathdir_pill_class_json.name or not pathdir_pill_class_json.is_dir():\n",
        "                continue\n",
        "\n",
        "            no_json = pathdir_pill_class_json.name.split('_')[0]\n",
        "            pathdir_pill_class = pathdir_pill_class_json.with_name(no_json)\n",
        "            pathdir_dest_class = pathdir_dest.joinpath(no_json)\n",
        "            pathdir_dest_class.mkdir(exist_ok=True)\n",
        "\n",
        "            for i,  pathfile_pill_json in enumerate(pathdir_pill_class_json.glob('*.json')):\n",
        "                # if i == 0 :\n",
        "                #     shutil.copy(pathfile_pill_json,pathdir_dest )\n",
        "                pathfile_pill_png = pathdir_pill_class.joinpath( pathfile_pill_json.stem + '.png')\n",
        "                copy_crop_pill_from_json(args, pathfile_pill_json, pathfile_pill_png, pathdir_dest_class.joinpath(pathfile_pill_json.stem + '.json'), pathdir_dest_class.joinpath(pathfile_pill_json.stem + '.png'))\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # job = 'hrnet_w64'\n",
        "#     job = 'resnet152'\n",
        "#     args = get_cli_args(job=job, run_phase='train', aug_level=1 )\n",
        "#     args.logger = utils.create_logging(args.file_log)\n",
        "#     copy_crop_pill_from_org(args)\n",
        "#     print('done')"
      ],
      "metadata": {
        "id": "tRe3XiGJLceJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "41298638-ba32-4919-95cb-cfdddc460dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c78fb4158a28>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **gen_pill.py**"
      ],
      "metadata": {
        "id": "7_1wJOZWLp-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from imgaug import augmenters as iaa\n",
        "from pathlib import Path\n",
        "import utils\n",
        "import make_label_sharpness\n",
        "from make_pill_class_list import get_pillid_from_pillfile\n",
        "from PIL import Image\n",
        "\n",
        "# https://github.com/aleju/imgaug\n",
        "\n",
        "list_level_aug_geo = [\n",
        "    [0, iaa.Identity()],\n",
        "]\n",
        "\n",
        "list_level_aug_geo_scale = [\n",
        "    [0, iaa.Identity()],\n",
        "    [1, iaa.Affine(scale=0.85)],\n",
        "    [2, iaa.Affine(scale=0.80)],\n",
        "    [3, iaa.Affine(scale=0.75)],\n",
        "    [3, iaa.Affine(scale=0.70)],\n",
        "\n",
        "]\n",
        "\n",
        "list_level_aug_geo_rotate = [\n",
        "    [0,iaa.Identity()],\n",
        "]\n",
        "\n",
        "list_level_aug_non_geo = [\n",
        "    [0,iaa.Identity()],\n",
        "    [1,iaa.GaussianBlur(sigma=1.0)],\n",
        "    [2,iaa.Dropout(p=0.05)],\n",
        "    [2,iaa.CoarseDropout(0.02, size_percent=0.5)],\n",
        "    [2,iaa.SaltAndPepper(0.1)],\n",
        "    [2,iaa.JpegCompression(compression=10)],\n",
        "    [3,iaa.ChangeColorTemperature(1000)],\n",
        "    [3,iaa.ChangeColorTemperature(4000)],\n",
        "    [3,iaa.Snowflakes(flake_size=0.1, speed=0.01)],\n",
        "    [3,iaa.GammaContrast(2.0)],\n",
        "]\n",
        "\n",
        "def rescaleToFit(np_image, np_point, fit_x, fit_y, scale_limit = 0.8):      #  scale_limit is for image rotation with nppoint.\n",
        "    np_image = np_image.copy()\n",
        "    h, w, c = np_image.shape\n",
        "    # show_cvimage(np_image)\n",
        "    scale = fit_x / w       # 먼저 x scale 을 정하고,\n",
        "    if scale * h > fit_y :  # scale이 h 에는  over height.\n",
        "        scale =  fit_y /  h # y scale으로 정한다.\n",
        "\n",
        "    scale = scale * scale_limit\n",
        "    np_image = cv2.resize(np_image, (int(round(w * scale)), int(round(h * scale)) ))\n",
        "    x_scale = np_image.shape[1] / w\n",
        "    y_scale = np_image.shape[0] / h\n",
        "\n",
        "    np_images_back = np.zeros((fit_y, fit_x, c), dtype=np.uint8)\n",
        "    x_offset = (fit_x - np_image.shape[1]) // 2\n",
        "    y_offset = (fit_y - np_image.shape[0]) // 2\n",
        "\n",
        "    np_images_back[y_offset:y_offset + np_image.shape[0], x_offset:x_offset+np_image.shape[1], : ] = np_image\n",
        "\n",
        "\n",
        "    if len(np_point) > 0:\n",
        "        np_point *= (x_scale, y_scale)\n",
        "\n",
        "        np_point[np_point < 0 ] += -1000\n",
        "        np_point += [x_offset, y_offset ]\n",
        "        np_point[np_point < 0 ] = -1\n",
        "\n",
        "    # draw_limbs_on_image(np_images_back,np_point, list_limb_digit0, (0, 0, 255), 2 , False )\n",
        "    # show_cvimage(np_images_back)\n",
        "\n",
        "    return np_images_back, np_point\n",
        "\n",
        "\n",
        "list_aug_geo = []\n",
        "list_aug_geo_scale=[]\n",
        "list_aug_geo_rotate = []\n",
        "list_aug_non_geo = []\n",
        "\n",
        "class Gen_Digit():\n",
        "    def __init__(self,args, dir_dataset,run_phase):\n",
        "        print(f'dataset dir is {dir_dataset}')\n",
        "\n",
        "        self.build_list_gen_based_on_level(args)\n",
        "        self.args = self.gen_pill_ready(args, dir_dataset, run_phase)\n",
        "\n",
        "    def build_list_gen_based_on_level(self, args):\n",
        "        global list_aug_geo, list_aug_geo_scale, list_aug_geo_rotate, list_aug_non_geo\n",
        "\n",
        "        print(f'run_phase is {args.run_phase}, aug_level is {args.aug_level}')\n",
        "\n",
        "        for i, (level, aug) in enumerate( list_level_aug_geo):\n",
        "            aug.name = f'g{i}'\n",
        "        for i, (level, aug) in enumerate( list_level_aug_geo_scale):\n",
        "            aug.name = f's{i}'\n",
        "        for i, (level, aug) in enumerate( list_level_aug_geo_rotate):\n",
        "            aug.name = f'r{i}'\n",
        "        for i, (level, aug) in enumerate( list_level_aug_non_geo):\n",
        "            aug.name = f'n{i}'\n",
        "\n",
        "        if args.run_phase == 'train' :\n",
        "            list_aug_geo = [ aug for level, aug in list_level_aug_geo if level <= args.aug_level]\n",
        "            list_aug_geo_scale = [aug for level, aug in list_level_aug_geo_scale if level <= args.aug_level]\n",
        "            list_aug_geo_rotate = [aug for level, aug in list_level_aug_geo_rotate if level <= args.aug_level]\n",
        "            list_aug_non_geo = [aug for level, aug in list_level_aug_non_geo if level <= args.aug_level]\n",
        "        else:\n",
        "            list_aug_geo = [iaa.Identity()]\n",
        "            list_aug_geo_scale = [iaa.Identity()]\n",
        "            list_aug_geo_rotate = [iaa.Identity()]\n",
        "            list_aug_non_geo = [iaa.Identity()]\n",
        "\n",
        "    def gen_pill_ready(self, args, dir_dataset, run_phase):\n",
        "        global list_aug_geo, list_aug_geo_scale, list_aug_geo_rotate, list_aug_non_geo\n",
        "        print(f'gen_type is {args.gen_type}, loading data ...')\n",
        "\n",
        "        path_dir_json = Path(dir_dataset)\n",
        "        if path_dir_json.is_dir() :\n",
        "            print(f'Gen :reading directory was not implemented')\n",
        "            self.len_total = 0\n",
        "\n",
        "        elif path_dir_json.is_file() and path_dir_json.suffix == '.json' and args.gen_type == 'read_only_image':\n",
        "\n",
        "            dict_temp = utils.read_dict_from_json(str(path_dir_json))\n",
        "            self.list_label_path = []\n",
        "            if args.gen_dataclass_sel in [ 'dataclass0', 'dataclass01'] :\n",
        "                if run_phase == 'train' :\n",
        "                    self.list_label_path += dict_temp.get('pngfile_class0_train', [])\n",
        "                    print(f'label_path was loaded from   <<< pngfile_class0_train >>>')\n",
        "                elif run_phase == 'valid' :\n",
        "                    self.list_label_path += dict_temp.get('pngfile_class0_valid', [])\n",
        "                    print(f'label_path was loaded from   <<< pngfile_class0_valid >>>')\n",
        "                else:\n",
        "                    self.list_label_path += dict_temp.get('pngfile_class0_test', [])\n",
        "                    print(f'label_path was loaded from   <<< pngfile_class0_test >>>')\n",
        "\n",
        "            if args.gen_dataclass_sel in [ 'dataclass1', 'dataclass01'] :\n",
        "                if run_phase == 'train' :\n",
        "                    self.list_label_path += dict_temp.get('pngfile_class1_train', [])\n",
        "                    print(f'label_path was loaded from   <<< pngfile_class1_train >>>')\n",
        "                elif run_phase == 'valid' :\n",
        "                    self.list_label_path += dict_temp.get('pngfile_class1_valid', [])\n",
        "                    print(f'label_path was loaded from   <<< pngfile_class1_valid >>>')\n",
        "                else:\n",
        "                    self.list_label_path += dict_temp.get('pngfile_class1_test',[])\n",
        "                    print(f'label_path was loaded from   <<< pngfile_class1_test >>>')\n",
        "\n",
        "            dict_pillid_label = make_label_sharpness.get_dict_pillid_label(args)\n",
        "            self.list_label_path = [(dict_pillid_label[get_pillid_from_pillfile(pngfile)], pngfile) for pngfile in self.list_label_path]\n",
        "\n",
        "            self.list_aug_geo = list_aug_geo\n",
        "            self.list_aug_geo_scale = list_aug_geo_scale\n",
        "            self.list_aug_geo_rotate = list_aug_geo_rotate\n",
        "            self.list_aug_non_geo = list_aug_non_geo\n",
        "\n",
        "            self.len_list_aug_geo = len(self.list_aug_geo)\n",
        "            self.len_list_aug_geo_scale = len(self.list_aug_geo_scale)\n",
        "            self.len_list_aug_geo_rotate = len(self.list_aug_geo_rotate)\n",
        "            self.len_list_aug_non_geo = len(self.list_aug_non_geo)\n",
        "            self.len_list_label_path = len(self.list_label_path)\n",
        "\n",
        "            self.len_total = self.len_list_aug_geo * self.len_list_aug_geo_scale * self.len_list_aug_geo_rotate * self.len_list_aug_non_geo * self.len_list_label_path\n",
        "            self.div_aug_geo = self.len_list_aug_geo_scale * self.len_list_aug_geo_rotate * self.len_list_aug_non_geo * self.len_list_label_path\n",
        "            self.div_aug_geo_scale = self.len_list_aug_geo_rotate * self.len_list_aug_non_geo * self.len_list_label_path\n",
        "            self.div_aug_geo_rotate = self.len_list_aug_non_geo * self.len_list_label_path\n",
        "            self.div_aug_non_geo = self.len_list_label_path\n",
        "\n",
        "        print(f\"data loading done.  dataset'length is {self.len_total}\")\n",
        "        return args\n",
        "\n",
        "\n",
        "    def generate_digits_by_index(self,args, index ) :\n",
        "        if args.gen_type == 'read_only_image' :\n",
        "\n",
        "            ind = index // self.div_aug_geo\n",
        "            mod = index % self.div_aug_geo\n",
        "\n",
        "            aug_geo = self.list_aug_geo[ind]\n",
        "\n",
        "            ind = mod // self.div_aug_geo_scale\n",
        "            mod = mod % self.div_aug_geo_scale\n",
        "\n",
        "            aug_geo_scale = self.list_aug_geo_scale[ind]\n",
        "\n",
        "            ind = mod // self.div_aug_geo_rotate\n",
        "            mod = mod % self.div_aug_geo_rotate\n",
        "\n",
        "            aug_geo_rotate = self.list_aug_geo_rotate[ind]\n",
        "\n",
        "            ind = mod // self.div_aug_non_geo\n",
        "            mod = mod % self.div_aug_non_geo\n",
        "\n",
        "            aug_non_geo = self.list_aug_non_geo[ind]\n",
        "            label, path_img = self.list_label_path[mod]\n",
        "            np_image = np.array(Image.open(path_img))\n",
        "\n",
        "            # np_image= aug_geo(image=np_image)\n",
        "            # np_image= aug_geo_scale(image=np_image)\n",
        "            # np_image= aug_geo_rotate(image=np_image)\n",
        "            # np_image= aug_non_geo(image=np_image)\n",
        "\n",
        "            iaaaug = iaa.Sequential([aug_geo, aug_geo_scale, aug_geo_rotate, aug_non_geo])\n",
        "            np_image = iaaaug(image=np_image)\n",
        "\n",
        "            aug_name = aug_geo.name + aug_geo_scale.name + aug_geo_rotate.name + aug_non_geo.name\n",
        "\n",
        "            return np_image, label, path_img, aug_name\n",
        "\n",
        "if __name__ == '__main__' :\n",
        "    print(f'done')"
      ],
      "metadata": {
        "id": "a1_KTLBTH5Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **get_cli_args.py**"
      ],
      "metadata": {
        "id": "bS-C4L-VMAOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import argparse\n",
        "import uuid\n",
        "\n",
        "is_debug = True\n",
        "def debugger_is_active() -> bool:\n",
        "    \"\"\"Return if the debugger is currently active\"\"\"\n",
        "    gettrace = getattr(sys, 'gettrace', lambda : None)\n",
        "    return gettrace() is not None\n",
        "\n",
        "is_debug = debugger_is_active()\n",
        "# print(f'is_debug is {is_debug}')        # debug 모드로 시작하면,  is_debug == True 이다.\n",
        "\n",
        "uuid_node = uuid.getnode()\n",
        "\n",
        "def get_cli_args(job='resnet152', run_phase = 'train', aug_level=0, dataclass='0'):\n",
        "    #######################################################################################################\n",
        "    print(f'job={job} run_phase:{run_phase} aug_level:{aug_level}, dataclass:{dataclass} ')\n",
        "    parser = argparse.ArgumentParser(description=__doc__, formatter_class=argparse.ArgumentDefaultsHelpFormatter, )\n",
        "\n",
        "    verbose = True\n",
        "    if os.name == 'nt':\n",
        "        dir_solution_home = r'D:\\proj_pill'\n",
        "        BATCH_SIZE = 2\n",
        "        num_workers = 2\n",
        "        num_threads = 1\n",
        "        dist_backend = 'gloo'\n",
        "        if job == 'resnet152':\n",
        "            BATCH_SIZE = 12\n",
        "\n",
        "    else:\n",
        "        dir_solution_home = r'/home/ubuntu/proj/proj_pill'\n",
        "        num_workers = 4\n",
        "        num_threads = 2\n",
        "        dist_backend = 'nccl'\n",
        "        BATCH_SIZE = 8\n",
        "        if uuid_node == 274973445269205:        # 광주AI\n",
        "            BATCH_SIZE = 56                     # train+valid:56 (opt을 올리지 않는다.), train:56\n",
        "            if job == 'hrnet_w64':\n",
        "                num_workers = 2\n",
        "                BATCH_SIZE = 32\n",
        "            if job == 'resnet152':\n",
        "                num_workers = 4\n",
        "                BATCH_SIZE = 64\n",
        "        elif uuid_node == 274973438730257:      # 광주AI2\n",
        "            BATCH_SIZE = 768\n",
        "            if job == 'paf_vgg19':\n",
        "                BATCH_SIZE = 512\n",
        "\n",
        "\n",
        "    if run_phase == 'valid'  and run_phase == 'test':\n",
        "        BATCH_SIZE = 1\n",
        "        num_workers = 1\n",
        "        num_threads = 1\n",
        "        verbose = False\n",
        "\n",
        "    DIR_DATA = os.path.join(dir_solution_home, 'pill_data')\n",
        "    DIR_PROJ = os.path.join(dir_solution_home, 'proj_pill')\n",
        "\n",
        "\n",
        "\n",
        "    # define directory\n",
        "    dir_pill_class_base = 'pill_data_croped'\n",
        "    json_pill_label_path_sharp_score = 'pill_label_path_sharp_score.json'\n",
        "    json_pill_prescription_type = 'pill_prescription_type.json'\n",
        "    json_pill_class_list = 'pill_class_list.json'\n",
        "\n",
        "    FITTOSIZE = 224\n",
        "    gen_type = 'read_only_image'\n",
        "    dataclass = f'dataclass{dataclass}'\n",
        "\n",
        "    if job == 'resnet152':\n",
        "        model_path_in = os.path.join(DIR_PROJ, f'pill_resnet152_{dataclass}_aug{aug_level}.pt')\n",
        "        model_path = os.path.join(DIR_PROJ, f'pill_resnet152_{dataclass}_aug{aug_level}.pt')\n",
        "\n",
        "\n",
        "\n",
        "    elif job == 'hrnet_w64':\n",
        "        model_path_in = os.path.join(DIR_PROJ, f'pill_hrnet_w64_{dataclass}_aug{aug_level}.pt')\n",
        "        model_path = os.path.join(DIR_PROJ, f'pill_hrnet_w64_{dataclass}_aug{aug_level}.pt')\n",
        "\n",
        "\n",
        "    #######################################################################################################\n",
        "\n",
        "\n",
        "    dir_pill_class_base = os.path.join(DIR_DATA, dir_pill_class_base)\n",
        "    json_pill_label_path_sharp_score = os.path.join(dir_pill_class_base, json_pill_label_path_sharp_score)\n",
        "    json_pill_prescription_type = os.path.join(dir_pill_class_base, json_pill_prescription_type)\n",
        "    dir_output = os.path.join(DIR_DATA, 'output')  # output dir for generation from gauge info\n",
        "\n",
        "\n",
        "\n",
        "    dir_log = './logs'\n",
        "    file_log = os.path.join(dir_log, f'log-{job}.txt')\n",
        "\n",
        "    #######################################################################################################\n",
        "    tqdm_desc_head = f'{job} aug_level:{aug_level} :'\n",
        "    print(f'BATCH_SIZE:{BATCH_SIZE}, num_workers:{num_workers}, num_threads:{num_threads} ')\n",
        "    #######################################################################################################\n",
        "    parser.add_argument('--size_image', default=FITTOSIZE, type=int, help='size of heatmap, vectmap')\n",
        "\n",
        "    parser.add_argument('--dir_log', default=dir_log, help='tensorboard log directory')\n",
        "    parser.add_argument('--file_log', default=file_log, help='tensorboard log directory')\n",
        "    parser.add_argument('--dir_pill_class_base', default=dir_pill_class_base, help='pill class valid directory')\n",
        "    parser.add_argument('--json_pill_label_path_sharp_score', default=json_pill_label_path_sharp_score, help='pill class sharpness')\n",
        "    parser.add_argument('--json_pill_prescription_type', default=json_pill_prescription_type, help='pill prescription_type')\n",
        "\n",
        "    parser.add_argument('--pill_dataset_class0', default=[90, 75], help='dataset camera latitude ')\n",
        "    parser.add_argument('--pill_dataset_class1', default=[70, 60], help='dataset camera latitude')\n",
        "\n",
        "    parser.add_argument('--pill_dataset_train_rate', default=0.8, help='dataset train rate')\n",
        "    parser.add_argument('--pill_dataset_valid_rate', default=0.1, help='dataset valid rate')\n",
        "    parser.add_argument('--pill_dataset_test_rate' , default=0.1, help='dataset test rate')\n",
        "    parser.add_argument('--num_classes', default=1000, help='pill dataset class number')\n",
        "\n",
        "    json_pill_class_list  = os.path.join(dir_pill_class_base, json_pill_class_list )\n",
        "    parser.add_argument('--json_pill_class_list', type=str, default=json_pill_class_list, help='json file for json_pill_class_list ')\n",
        "\n",
        "    parser.add_argument('--gen_type', default=gen_type, help='image only or annotation file')\n",
        "    parser.add_argument('--gen_dataclass_sel', default=dataclass, help='class0, class1, class01')\n",
        "    parser.add_argument('--cnn_name', default=job, help='classifier name')  # resnet152, hrnet_w64\n",
        "\n",
        "    # Default settings from https://arxiv.org/abs/1706.02677.\n",
        "    parser.add_argument('--batches_per_allreduce', type=int, default=1, help='number of batches processed locally before executing allreduce across workers; it multiplies total batch size.')\n",
        "    parser.add_argument('--fp16_allreduce', action='store_true', default=False, help='use fp16 compression during allreduce')\n",
        "    parser.add_argument('--use_adasum', action='store_true', default=False, help='use adasum algorithm to do reduction')\n",
        "    parser.add_argument('--gradient_predivide_factor', type=float, default=1.0, help='apply gradient predivide factor in optimizer (default: 1.0)')\n",
        "    parser.add_argument('--wd', type=float, default=0.0001, help='weight decay')\n",
        "    parser.add_argument('--momentum', type=float, default=0.9, help='SGD momentum')\n",
        "    parser.add_argument('--warmup_epochs', type=float, default=5, help='number of warmup epochs')\n",
        "    parser.add_argument('--epochs', type=int, default=150, help='number of epochs to train')\n",
        "    parser.add_argument('--disable_cuda', action='store_true', default=False, help='disables CUDA training')\n",
        "\n",
        "    parser.add_argument('--base_lr', type=float, default=0.001, help='learning rate for a single GPU')\n",
        "    parser.add_argument('--lr', '--learning_rate', default=0.001, type=float, metavar='LR', help='initial learning rate')\n",
        "    parser.add_argument('--pre_lr', type=float, default=1e-4, help='pre learning rate')\n",
        "\n",
        "    parser.add_argument('--lr_schedule', default=[60, 100, 140], help='lr scheduler')\n",
        "    # parser.add_argument('--lr_schedule', default=[3, ], help='lr scheduler')\n",
        "    parser.add_argument('--lr_gamma', default=0.1, help='lr scheduler')\n",
        "    parser.add_argument('--lr_factor', default=0.1, help='lr scheduler')\n",
        "\n",
        "    parser.add_argument('--batch_size', default=BATCH_SIZE, type=int, help='batch size')\n",
        "    parser.add_argument('--allreduce_batch_size', default=8, type=int, help='batch size')\n",
        "    parser.add_argument('--run_phase',  default=run_phase, help='train , valid')\n",
        "    parser.add_argument('--optimizer', default='sgd', help='select the optimizer in  sgd, adam, rmsprop')\n",
        "\n",
        "\n",
        "    parser.add_argument('--model_path', default=model_path, type=str, metavar='DIR', help='path to where the model saved')\n",
        "    parser.add_argument('--model_path_in', default=model_path_in, type=str, metavar='DIR', help='path to where the model saved')\n",
        "\n",
        "    #######################################################################################################\n",
        "    #######################################################################################################\n",
        "    vgg19_path = os.path.join(DIR_PROJ, 'paf_vgg19_level{aug_level}.pt')\n",
        "\n",
        "    dir_gauge_json = os.path.join(dir_solution_home, '민성기', 'digitGaugeSamples')\n",
        "    dir_gauge_json = os.path.join(dir_solution_home, '민성기', 'digitGaugeSamples2')\n",
        "    dir_gauge_json = os.path.join(dir_solution_home, '민성기', 'digitGaugeSamples3')\n",
        "    dir_gauge_json = os.path.join(dir_solution_home, '민성기', 'digitGaugeTest')\n",
        "    dir_class_basic = os.path.join(DIR_DATA, 'digit_class_base')\n",
        "    dir_class_basic_aug = os.path.join(DIR_DATA, 'digit_class_base_aug')\n",
        "\n",
        "    dir_digit_back = os.path.join(DIR_DATA, 'backimage')  # back image\n",
        "    dir_digit_anno = os.path.join(DIR_DATA, 'annotation')  # annotation\n",
        "    dir_digit_annoimage = os.path.join(DIR_DATA, 'annotationImage')  # annotation + image\n",
        "\n",
        "    dir_digit_paf = os.path.join(DIR_DATA, 'digit_paf_train')  # annotation + image\n",
        "    dir_digit_heat = os.path.join(DIR_DATA, 'digit_heat_train')  # annotation + image\n",
        "\n",
        "\n",
        "\n",
        "    parser.add_argument('--pre_n_images', default=8000, type=int, help='number of images to sampe for pretraining')\n",
        "    parser.add_argument('--n_images', default=None, type=int, help='number of images to sample')\n",
        "    parser.add_argument('--duplicate_data', default=None, type=int, help='duplicate data')\n",
        "\n",
        "\n",
        "    parser.add_argument('--nesterov', dest='nesterov', default=True, type=bool)\n",
        "    parser.add_argument('--print_freq', default=10, type=int, metavar='N', help='number of iterations to print the training statistics')\n",
        "    parser.add_argument('--freeze_base', default=0, type=int, help='number of epochs to train with frozen base')\n",
        "    parser.add_argument('--update_batchnorm_runningstatistics', default=False, action='store_true', help='update batch norm running statistics')\n",
        "    ########################################################################################################\n",
        "    # paf parameter\n",
        "\n",
        "    parser.add_argument('--stride', default=8, type=int, help='stride of heatmap, vectmap')\n",
        "    parser.add_argument('--train_scale', default=5, type=int, help='stride of heatmap, vectmap')\n",
        "    parser.add_argument('--num_pts_between_keypoints', default=10, type=int, help='the number of points between two keypoints ')\n",
        "    parser.add_argument('--ema', default=1e-3, type=float, help='ema decay constant')\n",
        "    parser.add_argument('--debug_without_plots', default=False, action='store_true', help='enable debug but dont plot')\n",
        "    parser.add_argument('--category_name', default='digit0', type=str, help='category name inside of annotation to process')\n",
        "    parser.add_argument('--model_factor', default=8, type=int, help='image downsampler factor')\n",
        "    parser.add_argument('--heatmap_threshold', default=0.05, type=float, help='heatmap  threshold')\n",
        "    parser.add_argument('--pafmap_threshold', default=0.01, type=float, help='pafmap threshold')\n",
        "    # parser.add_argument('--dataset_type', default='', type=str, help='dataset type')\n",
        "    parser.add_argument('--dataset_type', default='GenDigit', type=str, help='dataset type')\n",
        "\n",
        "    ########################################################################################################\n",
        "    # dataLoader parameter\n",
        "    parser.add_argument('--num_workers', default=num_workers if not is_debug else 1, type=int, help='number of workers for data loading')\n",
        "\n",
        "    # thread number for parallelizing cpu-bounding tensor operation\n",
        "    parser.add_argument('--num_threads', default=num_threads if not is_debug else 1, type=int, help='number of workers for tensor operations')\n",
        "\n",
        "    ########################################################################################################\n",
        "    # parameter for  makeImageFolder\n",
        "    # output directory parameter\n",
        "    parser.add_argument('--dir_gauge_json', default=dir_gauge_json, help='directory to get gauge inform as json type')\n",
        "    parser.add_argument('--dir_class_basic', default=dir_class_basic)\n",
        "\n",
        "    # for make_train_val_from_digit_class\n",
        "    # parser.add_argument('--dir_class_basic', default=dir_class_basic, help='digit base sample directory to split or for input directory')\n",
        "    parser.add_argument('--train_ratio', default=0.8, help='train data rate to split the amount of image')\n",
        "\n",
        "\n",
        "    # parser.add_argument('--dir_class_basic', default=dir_class_basic, help='directory to get gauge inform as json type')\n",
        "    parser.add_argument('--dir_class_basic_aug', default=dir_class_basic_aug)\n",
        "\n",
        "    parser.add_argument('--dir_digit_paf', default=dir_digit_paf)\n",
        "    parser.add_argument('--dir_digit_heat', default=dir_digit_heat)\n",
        "\n",
        "    #\n",
        "    parser.add_argument('-o', '--output', default='output.json', help='output file')\n",
        "    parser.add_argument('--dir_output', default=dir_output, help='output directory')\n",
        "\n",
        "    ########################################################################################################\n",
        "    # input parameter for  gen_digit\n",
        "    parser.add_argument('--aug_level', default=aug_level, help='augmentation level ')\n",
        "    parser.add_argument('--dir_digit_anno', default=dir_digit_anno, help='digit annotation directory')\n",
        "    parser.add_argument('--dir_digit_back', default=dir_digit_back, help='digit background directory')\n",
        "    parser.add_argument('--dir_digit_annoimage', default=dir_digit_annoimage, help='digit annotation and background directory')\n",
        "\n",
        "\n",
        "    parser.add_argument('--gen_digit_img_load_type', default='partial_load', help='load image and annotation on dram')  # whole_load, partial_load\n",
        "    parser.add_argument('--fittosize', default=FITTOSIZE, help='annotation file')  # gen_anno, read_anno\n",
        "    parser.add_argument('--normal', default=0.7, help='normalize to 1. for heatmap location')\n",
        "\n",
        "    ########################################################################################################\n",
        "    # parameter for  classifier.\n",
        "\n",
        "\n",
        "\n",
        "    ########################################################################################################\n",
        "    # parameter for  pytorch DistributedDataParallel.\n",
        "    parser.add_argument('--world_size', default=num_threads, type=int,help='전체 프로세스 수 - 마스터가 얼마나 많은 워커들을 기다릴지 알 수 있습니다')\n",
        "    parser.add_argument('--rank', default=1, type=int,help='각 프로세스의 우선순위 - 워커의 마스터 여부를 확인할 수 있습니다')\n",
        "    parser.add_argument('--dist_url', default='tcp://127.0.0.1:23456', type=str,help='url used to set up distributed training')\n",
        "    parser.add_argument('--dist_backend', default=dist_backend, type=str,help='distributed backend')\n",
        "    parser.add_argument('--seed', default=41, type=int,help='seed for initializing training. ')\n",
        "    parser.add_argument('--gpu', default=None, type=int,help='GPU id to use.')\n",
        "    parser.add_argument('--multiprocessing_distributed', action='store_true',default=True,\n",
        "                        help='Use multi-processing distributed training to launch '\n",
        "                             'N processes per node, which has N GPUs. This is the '\n",
        "                             'fastest way to use PyTorch for either single node or '\n",
        "                             'multi node data parallel training')\n",
        "\n",
        "    ########################################################################################################\n",
        "    # parameter for  pickle generation\n",
        "    pickle_list_cv_heat_paf_path_augname_label_level1 = os.path.join(DIR_DATA, 'data', 'list_cv_heat_paf_path_augname_label_level1.pickle')\n",
        "    pickle_list_cv_heat_paf_path_augname_label_level2 = os.path.join(DIR_DATA, 'data', 'list_cv_heat_paf_path_augname_label_level2.pickle')\n",
        "    parser.add_argument('--pickle_list_cv_heat_paf_path_augname_label_level1', default=pickle_list_cv_heat_paf_path_augname_label_level1, help='annotation image pickle file name definition')\n",
        "    parser.add_argument('--pickle_list_cv_heat_paf_path_augname_label_level2', default=pickle_list_cv_heat_paf_path_augname_label_level2, help='annotation image pickle file name definition')\n",
        "\n",
        "    ########################################################################################################\n",
        "    # parameter for  tqdm generation\n",
        "    parser.add_argument('--verbose', default=verbose,  help='display the progress and message')\n",
        "    parser.add_argument('--tqdm_desc_head', default=tqdm_desc_head, help='tqdm head message')\n",
        "\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # add args.device\n",
        "    args.device = torch.device('cpu')\n",
        "    args.pin_memory = False\n",
        "    args.cuda = False\n",
        "    if not args.disable_cuda and torch.cuda.is_available():\n",
        "        args.device = torch.device('cuda')\n",
        "        args.pin_memory = True\n",
        "        args.cuda = True\n",
        "\n",
        "    # os.makedirs(args.dir_output, exist_ok=True)\n",
        "    os.makedirs(args.dir_log, exist_ok=True)\n",
        "\n",
        "    return args\n"
      ],
      "metadata": {
        "id": "BiKh4MJIJx3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **main_cls0.py**"
      ],
      "metadata": {
        "id": "A2dFtlTuMQdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pill_classifier import *\n",
        "from get_cli_args import get_cli_args\n",
        "\n",
        "\n",
        "job = 'resnet152'\n",
        "if __name__ == '__main__':\n",
        "    job = 'resnet152'\n",
        "    args = get_cli_args(job=job, run_phase='test', aug_level=0, dataclass='0')\n",
        "\n",
        "    print(f'model_path_in is {args.model_path_in}')\n",
        "\n",
        "    end = time.time()\n",
        "    if args.run_phase == 'train'  :\n",
        "        args.dataset_train = Dataset_Pill(args, args.json_pill_class_list,  transform=transform_normalize, run_phase='train')\n",
        "        print(f'train dataset was loaded')\n",
        "\n",
        "    args.dataset_valid = Dataset_Pill(args, args.json_pill_class_list, transform=transform_normalize, run_phase='test' if args.run_phase == 'test' else 'valid')\n",
        "    print(f'valid dataset was loaded')\n",
        "\n",
        "\n",
        "    print(f'dataset loading time is {time.time() - end}')\n",
        "\n",
        "    pill_classifier(args)\n",
        "    print('job done')"
      ],
      "metadata": {
        "id": "6D9wtVOsM3XP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "afec99ee-ba17-4438-9784-92db9122835a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2befd5ad464f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpill_classifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mget_cli_args\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cli_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'resnet152'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pill_classifier'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **main_cls01_dir.py**"
      ],
      "metadata": {
        "id": "xcKWA3NEMYPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pill_classifier import *\n",
        "from get_cli_args import get_cli_args\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class Dataset_Dir(Dataset):\n",
        "    def __init__(self, args, dir_dataset, transform=None, target_transform=None, run_phase='train'):\n",
        "        self.args = args\n",
        "        self.dir_dataset = dir_dataset\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.list_images = [ png.name  for png in Path(dir_dataset).iterdir() if png.suffix == '.png']\n",
        "        self.run_phase = run_phase\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(os.path.join(self.dir_dataset, self.list_images[idx]))\n",
        "        label = 0\n",
        "        path_img = self.list_images[idx]\n",
        "        aug_name = \"\"\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "        if self.run_phase == 'valid' or self.run_phase == 'test':\n",
        "            return image, label, path_img, aug_name\n",
        "        else:\n",
        "            return image, label\n",
        "\n",
        "\n",
        "job = 'resnet152'\n",
        "if __name__ == '__main__':\n",
        "    # job = 'hrnet_w64'\n",
        "    job = 'resnet152'\n",
        "    args = get_cli_args(job=job, run_phase='test', aug_level=0, dataclass='01')\n",
        "\n",
        "    print(f'model_path_in is {args.model_path_in}')\n",
        "\n",
        "    dir_testimage = r'.\\dir_testimage'\n",
        "\n",
        "    args.dataset_valid = Dataset_Dir(args, dir_testimage, transform=transform_normalize, run_phase='test' if args.run_phase == 'test' else 'valid')\n",
        "    args.batch_size = len(args.dataset_valid)\n",
        "    args.verbose = False\n",
        "    print(f'valid dataset was loaded')\n",
        "\n",
        "    pill_classifier(args)\n",
        "\n",
        "    print(args.path_img)\n",
        "    print(args.list_preds)\n",
        "    print('job done')"
      ],
      "metadata": {
        "id": "i6_O4H18M-b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **main_cls1.py**"
      ],
      "metadata": {
        "id": "Ijg59q82Mbvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pill_classifier import *\n",
        "from get_cli_args import get_cli_args\n",
        "\n",
        "\n",
        "job = 'resnet152'\n",
        "if __name__ == '__main__':\n",
        "    # job = 'hrnet_w64'\n",
        "    job = 'resnet152'\n",
        "    args = get_cli_args(job=job, run_phase='test', aug_level=0, dataclass='1')\n",
        "\n",
        "    print(f'model_path_in is {args.model_path_in}')\n",
        "\n",
        "    end = time.time()\n",
        "    if args.run_phase == 'train'  :\n",
        "        args.dataset_train = Dataset_Pill(args, args.json_pill_class_list,  transform=transform_normalize, run_phase='train')\n",
        "        print(f'train dataset was loaded')\n",
        "\n",
        "    args.dataset_valid = Dataset_Pill(args, args.json_pill_class_list, transform=transform_normalize, run_phase='test' if args.run_phase == 'test' else 'valid')\n",
        "    print(f'valid dataset was loaded')\n",
        "\n",
        "\n",
        "    print(f'dataset loading time is {time.time() - end}')\n",
        "\n",
        "    pill_classifier(args)\n",
        "    print('job done')"
      ],
      "metadata": {
        "id": "sxbY59RvNF5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **main_cls01.py**"
      ],
      "metadata": {
        "id": "Odu5HEkVMivM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pill_classifier import *\n",
        "from get_cli_args import get_cli_args\n",
        "\n",
        "\n",
        "job = 'resnet152'\n",
        "if __name__ == '__main__':\n",
        "    # job = 'hrnet_w64'\n",
        "    job = 'resnet152'\n",
        "    args = get_cli_args(job=job, run_phase='test', aug_level=0, dataclass='01')\n",
        "\n",
        "    print(f'model_path_in is {args.model_path_in}')\n",
        "\n",
        "    end = time.time()\n",
        "    if args.run_phase == 'train'  :\n",
        "        args.dataset_train = Dataset_Pill(args, args.json_pill_class_list,  transform=transform_normalize, run_phase='train')\n",
        "        print(f'train dataset was loaded')\n",
        "\n",
        "    args.dataset_valid = Dataset_Pill(args, args.json_pill_class_list, transform=transform_normalize, run_phase='test' if args.run_phase == 'test' else 'valid')\n",
        "    print(f'valid dataset was loaded')\n",
        "\n",
        "\n",
        "    print(f'dataset loading time is {time.time() - end}')\n",
        "\n",
        "    pill_classifier(args)\n",
        "    print('job done')"
      ],
      "metadata": {
        "id": "hLEOmA71NRIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **make_label_sharpness.py**"
      ],
      "metadata": {
        "id": "hzBc2OLvMnpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "from get_cli_args import get_cli_args\n",
        "from pathlib import Path\n",
        "import utils\n",
        "import numpy\n",
        "\n",
        "def estimate_sharpness(image: numpy.array, threshold: int = 100):\n",
        "    if image.ndim == 3:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    blur_map = cv2.Laplacian(image, cv2.CV_64F)\n",
        "    score = numpy.var(blur_map)\n",
        "    return score\n",
        "\n",
        "def make_label_sharpness(args):\n",
        "    pathdir_dest = Path(args.dir_pill_class_base)\n",
        "    dict_pill_prescription_type = utils.read_dict_from_json(args.json_pill_prescription_type)['pill_prescription_type']\n",
        "\n",
        "    list_pills_pres_sharp_score = []\n",
        "    list_pills_otc_sharp_score = []\n",
        "    count = 0\n",
        "    for pathdir_pill_class in pathdir_dest.iterdir():\n",
        "        if not pathdir_pill_class.is_dir() :\n",
        "            continue\n",
        "        print(f'{count}, {pathdir_pill_class} is being estimated')\n",
        "        count += 1\n",
        "        list_pill_class_shape_score = []\n",
        "        for  pathfile_pill_png in pathdir_pill_class.iterdir():\n",
        "            if pathfile_pill_png.suffix == '.json':\n",
        "                continue\n",
        "            score = estimate_sharpness(utils.open_opencv_file(str(pathfile_pill_png)))\n",
        "            list_pill_class_shape_score.append(score)\n",
        "\n",
        "        score_min = min(list_pill_class_shape_score)\n",
        "        score_max = max(list_pill_class_shape_score)\n",
        "        score_mean = sum(list_pill_class_shape_score)/len(list_pill_class_shape_score)\n",
        "        if dict_pill_prescription_type[pathdir_pill_class.stem] == 'PRES':\n",
        "            list_pills_pres_sharp_score.append([str(pathdir_pill_class.stem), score_mean, score_min,score_max])\n",
        "        elif dict_pill_prescription_type[pathdir_pill_class.stem] == 'OTC':\n",
        "            list_pills_otc_sharp_score.append([str(pathdir_pill_class.stem), score_mean, score_min,score_max])\n",
        "\n",
        "    list_pills_pres_sharp_score = sorted(list_pills_pres_sharp_score, key=lambda a: a[2], reverse=True)         # sharp min 기준으로 정렬.\n",
        "    list_pills_otc_sharp_score = sorted(list_pills_otc_sharp_score, key=lambda a: a[2], reverse=True)           # sharp min 기준으로 정렬.\n",
        "    list_pills_label_path_sharp_score = [ [label, pathname, score_mean, score_min, score_max] for label, ( pathname, score_mean, score_min, score_max ) in enumerate(list_pills_pres_sharp_score) if label < 600]\n",
        "    list_pills_label_path_sharp_score += [[label+600, pathname, score_mean, score_min, score_max] for label, (pathname, score_mean, score_min, score_max) in enumerate(list_pills_otc_sharp_score) if label < 400]\n",
        "\n",
        "    dict_temp = { 'pill_label_path_sharp_score':list_pills_label_path_sharp_score}\n",
        "\n",
        "    utils.save_dict_to_json(dict_temp, args.json_pill_label_path_sharp_score)\n",
        "\n",
        "def get_dict_label_pillid(args):\n",
        "    dict_temp = utils.read_dict_from_json(args.json_pill_label_path_sharp_score)\n",
        "    list_pills_label_path_sharp_score = dict_temp['pill_label_path_sharp_score']\n",
        "\n",
        "    dict_label_pillid = {}\n",
        "    for idx , (label, pillid, score_mean, score_min, score_max) in enumerate(list_pills_label_path_sharp_score) :\n",
        "        if idx >= args.num_classes:\n",
        "            break\n",
        "        # print(f'{label},{pillid},{score_mean},{score_min},{score_max}')\n",
        "        dict_label_pillid.update({label: pillid})\n",
        "\n",
        "    return dict_label_pillid\n",
        "\n",
        "\n",
        "def get_dict_pillid_label(args):\n",
        "    dict_temp = utils.read_dict_from_json(args.json_pill_label_path_sharp_score)\n",
        "    list_pills_label_path_sharp_score = dict_temp['pill_label_path_sharp_score']\n",
        "\n",
        "    dict_label_pillid = {}\n",
        "    for idx, (label, pillid, score_mean, score_min, score_max) in enumerate(list_pills_label_path_sharp_score):\n",
        "        if idx >= args.num_classes:\n",
        "            break\n",
        "        dict_label_pillid.update({pillid:label})\n",
        "\n",
        "    return dict_label_pillid\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # job = 'hrnet_w64'\n",
        "    job = 'resnet152'\n",
        "    args = get_cli_args(job=job, run_phase='train', aug_level=1, dataclass='0')\n",
        "    args.logger = utils.create_logging(args.file_log)\n",
        "    make_label_sharpness(args)\n",
        "    # get_dict_pillid_label(args)\n",
        "    # dict_label_pillid = get_dict_label_pillid(args)\n",
        "    print('done')\n"
      ],
      "metadata": {
        "id": "nLMJFNf5NSHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**make_pill_class_list.py**"
      ],
      "metadata": {
        "id": "zOfquQnhMs_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "from get_cli_args import get_cli_args\n",
        "import utils\n",
        "from pathlib import Path\n",
        "import random\n",
        "import os\n",
        "\n",
        "def get_pill_info_from_pillfile(path_png):\n",
        "    pill_basename, pill_status, pill_back, pill_front, pill_light, pill_lati, pill_longi, pill_dist = path_png.stem.split('_')\n",
        "    pill_status, pill_back, pill_front, pill_light, pill_lati, pill_longi, pill_dist = int(pill_status), int(pill_back), int(pill_front), int(pill_light), int(pill_lati), int(pill_longi), int(pill_dist)\n",
        "    return pill_basename, pill_status, pill_back, pill_front, pill_light, pill_lati, pill_longi, pill_dist\n",
        "\n",
        "def get_pillid_from_pillfile(file_png):\n",
        "    try :\n",
        "        pill_basename, pill_status, pill_back, pill_front, pill_light, pill_lati, pill_longi, pill_dist = Path(file_png).stem.split('_')\n",
        "    except:\n",
        "        # 상위 dir의  name이  pill id가 된다.\n",
        "        path_file = Path(file_png)\n",
        "        pill_basename = path_file.parts[-2]\n",
        "    return pill_basename\n",
        "\n",
        "def make_pill_class_list(args):\n",
        "    '''\n",
        "    json_pill_sharpness 파일으로 부터, dataset을 만든다.\n",
        "    class 1 :  카메라 위도, 90, 75\n",
        "    class 2 : 카메라 위도 70, 65\n",
        "    :param args:\n",
        "    :return:\n",
        "    train set : 90%\n",
        "    valid set : 10%\n",
        "    test set : 10%\n",
        "    '''\n",
        "\n",
        "    pill_class0 = []\n",
        "    pill_class1 = []\n",
        "    dict_temp = utils.read_dict_from_json(args.json_pill_label_path_sharp_score)\n",
        "    list_pills_label_pillid_sharp_score = dict_temp['pill_label_path_sharp_score']\n",
        "    for label, pillid, score_mean, score_min, score_max in list_pills_label_pillid_sharp_score:\n",
        "        if label >= args.num_classes:\n",
        "            continue\n",
        "        print(f'reading sharp score.  label:{label}')\n",
        "        pillid = Path(os.path.join(args.dir_pill_class_base, pillid))\n",
        "        for file_png in pillid.iterdir():\n",
        "            if file_png.suffix != '.png':\n",
        "                continue\n",
        "\n",
        "            pill_basename, pill_status, pill_back, pill_front, pill_light, pill_lati, pill_longi, pill_dist = get_pill_info_from_pillfile(file_png)\n",
        "\n",
        "            if pill_lati in args.pill_dataset_class0:\n",
        "                pill_class0.append(str(file_png))\n",
        "            elif pill_lati in args.pill_dataset_class1:\n",
        "                pill_class1.append(str(file_png))\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "    list_index_class0 = list(range(len(pill_class0)))\n",
        "    len_train = int(round(args.pill_dataset_train_rate * len(list_index_class0)))\n",
        "    list_index_class0_train = random.sample(list_index_class0, len_train)\n",
        "    list_index_class0_valid = list(set(list_index_class0) - set(list_index_class0_train))\n",
        "    list_index_class0_test = random.sample(list_index_class0_valid, int(round(len(list_index_class0_valid) * (args.pill_dataset_test_rate / (args.pill_dataset_test_rate + args.pill_dataset_valid_rate)))))\n",
        "    list_index_class0_valid = list(set(list_index_class0_valid) - set(list_index_class0_test))\n",
        "\n",
        "    list_index_class1 = list(range(len(pill_class1)))\n",
        "    len_train = int(round(args.pill_dataset_train_rate * len(list_index_class1)))\n",
        "    list_index_class1_train = random.sample(list_index_class1, len_train)\n",
        "    list_index_class1_valid = list(set(list_index_class1) - set(list_index_class1_train))\n",
        "    list_index_class1_test = random.sample(list_index_class1_valid, int(round(len(list_index_class1_valid) * (args.pill_dataset_test_rate / (args.pill_dataset_test_rate + args.pill_dataset_valid_rate)))))\n",
        "    list_index_class1_valid = list(set(list_index_class1_valid) - set(list_index_class1_test))\n",
        "\n",
        "    list_pngfile_class0_train = [pill_class0[index] for index in list_index_class0_train]\n",
        "    list_pngfile_class0_valid = [pill_class0[index] for index in list_index_class0_valid]\n",
        "    list_pngfile_class0_test = [pill_class0[index] for index in list_index_class0_test]\n",
        "\n",
        "    list_pngfile_class1_train = [pill_class1[index] for index in list_index_class1_train]\n",
        "    list_pngfile_class1_valid = [pill_class1[index] for index in list_index_class1_valid]\n",
        "    list_pngfile_class1_test = [pill_class1[index] for index in list_index_class1_test]\n",
        "\n",
        "    print(f'pngfile_class0_train:{len(list_pngfile_class0_train)}')\n",
        "    print(f'pngfile_class0_valid:{len(list_pngfile_class0_valid)}')\n",
        "    print(f'pngfile_class0_test:{len(list_pngfile_class0_test)}')\n",
        "\n",
        "    print(f'pngfile_class1_train:{len(list_pngfile_class1_train)}')\n",
        "    print(f'pngfile_class1_valid:{len(list_pngfile_class1_valid)}')\n",
        "    print(f'pngfile_class1_test:{len(list_pngfile_class1_test)}')\n",
        "\n",
        "    dict_temp = {'pngfile_class0_train': list_pngfile_class0_train, 'pngfile_class0_valid': list_pngfile_class0_valid, 'pngfile_class0_test': list_pngfile_class0_test, 'pngfile_class1_train': list_pngfile_class1_train, 'pngfile_class1_valid': list_pngfile_class1_valid, 'pngfile_class1_test': list_pngfile_class1_test, }\n",
        "\n",
        "    utils.save_dict_to_json(dict_temp, args.json_pill_class_list)\n",
        "\n",
        "def rename_non_candidate_to_s_id(args):\n",
        "    # 후보가 아닌 알약 directory을  다른 이름(K head)으로 변경한다.\n",
        "    dict_temp = utils.read_dict_from_json(args.json_pill_label_path_sharp_score)\n",
        "    list_pills_label_pillid_sharp_score = dict_temp['pill_label_path_sharp_score']\n",
        "    list_candidate_ids = [ pillid for label, pillid, score_mean, score_min, score_max in list_pills_label_pillid_sharp_score ]\n",
        "\n",
        "    path_pill_base = Path(args.dir_pill_class_base )\n",
        "    list_pill_all_id = []\n",
        "    for pill_dir in path_pill_base.iterdir():\n",
        "        if not pill_dir.is_dir() :\n",
        "            continue\n",
        "        list_pill_all_id.append(pill_dir.stem)\n",
        "\n",
        "    list_non_candidate_pillid = list( set(list_pill_all_id) - set(list_candidate_ids))\n",
        "\n",
        "    for pillid in list_non_candidate_pillid :\n",
        "        new_id = pillid.replace('K', 'S')\n",
        "        path_old = os.path.join(args.dir_pill_class_base, pillid)\n",
        "        path_new = os.path.join(args.dir_pill_class_base, new_id)\n",
        "        shutil.move(path_old, path_new)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # job = 'hrnet_w64'\n",
        "    job = 'resnet152'\n",
        "    args = get_cli_args(job=job, run_phase='train', aug_level=1, dataclass='0')\n",
        "    args.logger = utils.create_logging(args.file_log)\n",
        "    # make_pill_class_list(args)\n",
        "    rename_non_candidate_to_s_id(args)\n",
        "    print('job done')\n"
      ],
      "metadata": {
        "id": "wQ96F8I6K53M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**pill_classifier_hvd.py**"
      ],
      "metadata": {
        "id": "UZol2gyfMyED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from get_cli_args import get_cli_args\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from hrnet import get_hrnet\n",
        "from utils import model_load, transform_normalize, get_optimizer\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.multiprocessing as mp\n",
        "from pill_classifier import get_pill_model, Dataset_Pill, run_model\n",
        "import horovod.torch as hvd\n",
        "\n",
        "\n",
        "def adjust_learning_rate_hvd(args, optimizer, len_loader, epoch, batch_idx):\n",
        "    if epoch < args.warmup_epochs:\n",
        "        epoch += float(batch_idx + 1) / len_loader\n",
        "        lr_adj = 1. / hvd.size() * (epoch * (hvd.size() - 1) / args.warmup_epochs + 1)\n",
        "    elif epoch < 30:\n",
        "        lr_adj = 1.\n",
        "    elif epoch < 60:\n",
        "        lr_adj = 1e-1\n",
        "    elif epoch < 80:\n",
        "        lr_adj = 1e-2\n",
        "    else:\n",
        "        lr_adj = 1e-3\n",
        "\n",
        "    lr = args.base_lr * hvd.size() * args.batches_per_allreduce * lr_adj\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    return lr\n",
        "\n",
        "def pill_classifier_hvd(args):\n",
        "    # pytorch의 DataLoader 함수를 사용할 때 num_workers>1인 경우를  지원해서, fork가 지원되게.\n",
        "    torch.multiprocessing.freeze_support()\n",
        "    print(f'model path is {args.model_path_in}')\n",
        "\n",
        "    args.allreduce_batch_size = args.batch_size * args.batches_per_allreduce\n",
        "\n",
        "    hvd.init()\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "    if args.cuda:\n",
        "        # Horovod: pin GPU to local rank.\n",
        "        torch.cuda.set_device(hvd.local_rank())\n",
        "        torch.cuda.manual_seed(args.seed)\n",
        "        args.gpu = hvd.local_rank()\n",
        "\n",
        "    cudnn.benchmark = True  # 내장된 cudnn 자동 튜너를 활성화하여, 하드웨어에 맞게 사용할 최상의 알고리즘(텐서 크기나 conv 연산에 맞게?)을 찾는다.\n",
        "                            # 입력 이미지 크기가 자주 변하지 않는다면, 초기 시간이 소요되지만 일반적으로 더 빠른 런타임의 효과를 볼 수 있다\n",
        "    torch.backends.cudnn.deterministic = False      # 만일 True이면, cudnn에 맞추는 알고리즘이 없으면, Raise Error가 된다.\n",
        "    torch.backends.cudnn.enabled = True\n",
        "\n",
        "    verbose = args.verbose if hvd.rank() == 0 else False\n",
        "    args.rank = hvd.rank()\n",
        "\n",
        "    # Horovod: write TensorBoard logs on first worker.\n",
        "    log_writer = SummaryWriter(args.dir_log) if hvd.rank() == 0 else None\n",
        "\n",
        "    # Horovod: limit # of CPU threads to be used per worker.\n",
        "    torch.set_num_threads(args.num_threads)\n",
        "\n",
        "    kwargs = {'num_workers': args.num_workers, 'pin_memory': True} if args.cuda else {}\n",
        "\n",
        "    # When supported, use 'forkserver' to spawn dataloader workers instead of 'fork' to prevent\n",
        "    # issues with Infiniband implementations that are not fork-safe\n",
        "    if (kwargs.get('num_workers', 0) > 0 and hasattr(mp, '_supports_context') and\n",
        "        mp._supports_context and 'forkserver' in mp.get_all_start_methods()):\n",
        "        kwargs['multiprocessing_context'] = 'forkserver'\n",
        "\n",
        "    #############################################################################\n",
        "    print(\"Loading dataset...\")\n",
        "\n",
        "    if args.run_phase == 'train':\n",
        "        dataset_train = Dataset_Pill(args, args.json_pill_class_list, transform=transform_normalize, run_phase='train')\n",
        "        sampler_train = torch.utils.data.distributed.DistributedSampler(dataset_train, num_replicas=hvd.size(), rank=hvd.rank())\n",
        "        dataloader_train = DataLoader(dataset_train, batch_size=args.batch_size, sampler=sampler_train, **kwargs)\n",
        "\n",
        "    dataset_valid = Dataset_Pill(args, args.json_pill_class_list, transform=transform_normalize, run_phase='valid')\n",
        "    sampler_valid = torch.utils.data.distributed.DistributedSampler(dataset_valid, num_replicas=hvd.size(), rank=hvd.rank())\n",
        "    dataloader_valid = DataLoader(dataset_valid, batch_size=args.batch_size, sampler=sampler_valid, **kwargs)\n",
        "\n",
        "\n",
        "    model = get_pill_model(args)\n",
        "\n",
        "    # define loss function (criterion) and optimizer\n",
        "    criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "    optimizer = get_optimizer(args, model)\n",
        "    compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none\n",
        "\n",
        "    optimizer = hvd.DistributedOptimizer(\n",
        "        optimizer, named_parameters=model.named_parameters(),\n",
        "        compression=compression,\n",
        "        backward_passes_per_step=args.batches_per_allreduce,\n",
        "        op=hvd.Adasum if args.use_adasum else hvd.Average,\n",
        "        gradient_predivide_factor=args.gradient_predivide_factor)\n",
        "\n",
        "    epoch_begin, dict_checkpoint, success = model_load(args, model, optimizer)\n",
        "    epoch_begin = hvd.broadcast(torch.tensor(epoch_begin), root_rank=0, name='epoch_begin').item()\n",
        "\n",
        "    # Horovod: broadcast parameters & optimizer state.\n",
        "    hvd.broadcast_parameters(model.state_dict(), root_rank=0)\n",
        "    hvd.broadcast_optimizer_state(optimizer, root_rank=0)           # optimizer.state_dict()가 아니다. optimizer가 들어간다.\n",
        "\n",
        "\n",
        "    run_model(args, model, dataloader_train, dataloader_valid, sampler_train, sampler_valid, criterion,optimizer, epoch_begin, log_writer, verbose  )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # job = 'hrnet_w64'\n",
        "    job = 'resnet152'\n",
        "    args = get_cli_args(job=job, run_phase='train', aug_level=0, dataclass='0')\n",
        "    pill_classifier_hvd(args)\n",
        "\n",
        "    print('job done')"
      ],
      "metadata": {
        "id": "RnET5Dh4M0yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**pill_classifier.py**"
      ],
      "metadata": {
        "id": "sCao1a5fM2h8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from get_cli_args import get_cli_args\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from gen_pill import Gen_Digit\n",
        "from hrnet import get_hrnet\n",
        "from utils import model_load, model_save, accuracy, get_optimizer, transform_normalize, AverageMeter, adjust_learning_rate\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "\n",
        "class Dataset_Pill(Dataset):\n",
        "    def __init__(self, args, dir_dataset, transform=None, target_transform=None, run_phase='train'):\n",
        "        self.args = args\n",
        "        self.gen_digit = Gen_Digit(args, dir_dataset, run_phase)\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.run_phase = run_phase\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.gen_digit.len_total\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label, path_img, aug_name = self.gen_digit.generate_digits_by_index(self.args, idx)\n",
        "\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform is not None:\n",
        "            label = self.target_transform(label)\n",
        "        if self.run_phase == 'valid' or self.run_phase == 'test':\n",
        "            return image, label, path_img, aug_name\n",
        "        else:\n",
        "            return image, label\n",
        "\n",
        "def get_pill_model(args):\n",
        "\n",
        "    if args.cnn_name == 'resnet152' :\n",
        "        model = models.resnet152(num_classes=args.num_classes)\n",
        "    elif args.cnn_name == 'hrnet_w64' :\n",
        "        model = get_hrnet()\n",
        "        model.classifier = nn.Linear(in_features=2048, out_features=args.num_classes, bias=True)\n",
        "    else:\n",
        "        raise Exception('No Found CNN Name')\n",
        "\n",
        "    if args.cuda == True:\n",
        "        if args.gpu is not None:\n",
        "            model.cuda(args.gpu)\n",
        "        else:\n",
        "            model.cuda()\n",
        "    else:\n",
        "        model.cpu()\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def train(args, dataloader, sampler, model, criterion, optimizer, epoch, log_writer=None, verbose=True):\n",
        "    model.train()\n",
        "    if sampler != None:\n",
        "        sampler.set_epoch(epoch)\n",
        "\n",
        "    metric_train_loss = AverageMeter()\n",
        "    ametric_data_time = AverageMeter()\n",
        "\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "\n",
        "    end = time.time()\n",
        "    lr = optimizer.param_groups[0]['lr']\n",
        "    with tqdm(total=len(dataloader), desc=args.tqdm_desc_head + 'Train Epoch  #{}'.format(epoch), disable=not verbose) as t:\n",
        "        for batch_idx, (img, target) in enumerate(dataloader):\n",
        "            if args.cuda:\n",
        "                img = img.cuda()\n",
        "                target = target.cuda()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(img)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            prec1, prec5 = accuracy(output, target, (1, 5))\n",
        "            count_try = img.cpu().shape[0]\n",
        "            top1.update(prec1[0].detach().cpu().item(), count_try)\n",
        "            top5.update(prec5[0].detach().cpu().item(), count_try)\n",
        "\n",
        "            metric_train_loss.update(loss.detach().cpu().item(), count_try)\n",
        "            t.set_postfix({'loss': metric_train_loss.avg, 'lr':lr,  'top1':top1.avg, 'top5':top5.avg })\n",
        "            t.update(1)\n",
        "\n",
        "    ametric_data_time.update(time.time() - end)\n",
        "\n",
        "    if log_writer:\n",
        "        log_writer.add_scalar('train/loss', metric_train_loss.avg, epoch)\n",
        "\n",
        "    try:\n",
        "        print_string = 'Epoch: [{0}][{1}/{2}]\\t'.format(epoch, batch_idx, len(dataloader))\n",
        "        print_string += 'Data time {data_time.val:.3f} ({data_time.avg:.3f} Now:{Now})\\t'.format(data_time=ametric_data_time, Now=datetime.datetime.now())\n",
        "        print_string += 'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(loss=metric_train_loss)\n",
        "        print_string += 'Accuracy top1:{top1.avg:.4f}, top5:{top5.avg:.4f}'.format(top1=top1, top5=top5)\n",
        "        print(print_string)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return metric_train_loss.avg\n",
        "\n",
        "\n",
        "def valid(args, dataloader, sampler,  model, criterion, epoch, log_writer=None, verbose=True):\n",
        "    metric_train_loss = AverageMeter()\n",
        "    ametric_data_time = AverageMeter()\n",
        "\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    if sampler != None:\n",
        "        sampler.set_epoch(epoch)\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    args.list_preds = []\n",
        "    args.list_target = []\n",
        "    args.count_correct = 0\n",
        "    with torch.no_grad():\n",
        "        with tqdm(total=len(dataloader), desc=args.tqdm_desc_head + '{} Epoch  #{}'.format( args.run_phase, epoch), disable=not verbose) as t:\n",
        "            for i, (img, target, path_img, aug_name ) in enumerate(dataloader):\n",
        "                # measure data loading time\n",
        "\n",
        "                if args.cuda:\n",
        "                    img = img.cuda()\n",
        "                    target = target.cuda()\n",
        "\n",
        "                output = model(img)\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "                prec1, prec5 = accuracy(output, target, (1, 5))\n",
        "\n",
        "                if ( prec1[0].detach().cpu().item() != 100.):\n",
        "                    if args.run_phase == 'valid': print(f'<------- class valid fail file: {path_img[0]}, aug_name:{aug_name}')\n",
        "\n",
        "                preds = output.data.max(dim=1, keepdim=True)[1]\n",
        "                count_correct = preds.eq(target.data.view_as(preds)).cpu().sum()\n",
        "                list_preds = preds.view(-1).tolist()\n",
        "\n",
        "                args.list_preds = list_preds\n",
        "                args.list_target = target.detach().cpu().tolist()\n",
        "                args.count_correct = count_correct.item()\n",
        "                count_try = img.cpu().shape[0]\n",
        "                top1.update(prec1[0].detach().cpu().item(), count_try)\n",
        "                top5.update(prec5[0].detach().cpu().item(), count_try)\n",
        "\n",
        "                metric_train_loss.update(loss.detach().cpu().item(), count_try)\n",
        "\n",
        "                t.set_postfix({'loss': metric_train_loss.avg, 'top1': top1.avg, 'top5': top5.avg})\n",
        "                t.update(1)\n",
        "\n",
        "    ametric_data_time.update(time.time() - end)\n",
        "\n",
        "    if log_writer:\n",
        "        log_writer.add_scalar('validation/loss', metric_train_loss.avg, epoch)\n",
        "\n",
        "    try:\n",
        "        print_string = 'Epoch: [{0}][{1}/{2}]\\t'.format(epoch, i, len(dataloader))\n",
        "        print_string += 'Data time {data_time.val:.3f} ({data_time.avg:.3f} Now:{Now})\\t'.format(data_time=ametric_data_time, Now=datetime.datetime.now())\n",
        "        print_string += 'Loss {loss.val:.4f} ({loss.avg:.4f})'.format(loss=metric_train_loss)\n",
        "        print_string += 'Accuracy top1:{top1.avg:.4f}, top5:{top5.avg:.4f}'.format(top1=top1, top5=top5)\n",
        "        print(print_string)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return metric_train_loss.avg\n",
        "\n",
        "def run_model(args, model, dataloader_train, dataloader_valid, sampler_train, sampler_valid, criterion,optimizer, epoch_begin, log_writer, verbose=True  ):\n",
        "    if args.run_phase == 'valid' or args.run_phase == 'test':\n",
        "        print(time.asctime())\n",
        "        valid(args, dataloader_valid, sampler_valid,  model, criterion, 0, log_writer)\n",
        "        print(time.asctime())\n",
        "        return\n",
        "\n",
        "    lr_scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=2, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=3, min_lr=0, eps=1e-08)\n",
        "\n",
        "\n",
        "    best_perf = 1000\n",
        "    for epoch in range(epoch_begin, args.epochs):   # ( 0:100)\n",
        "        # adjust_learning_rate(args, optimizer, epoch)\n",
        "        # train for one epoch\n",
        "        perf_indicator = train(args, dataloader_train, sampler_train, model, criterion, optimizer, epoch, log_writer, verbose)\n",
        "        if epoch > 10:\n",
        "            perf_indicator = valid(args, dataloader_valid,sampler_valid, model, criterion, epoch, log_writer,verbose)\n",
        "            if (args.gpu == 0):\n",
        "                print(f'perf_indicator:{perf_indicator} ,  best_perf:{best_perf}')\n",
        "            if perf_indicator < best_perf:\n",
        "                model_save(args.model_path, epoch, model, optimizer, args.rank)\n",
        "                best_perf = perf_indicator\n",
        "        else:\n",
        "            model_save(args.model_path, epoch, model, optimizer, args.rank)\n",
        "            best_perf = perf_indicator\n",
        "\n",
        "        lr_scheduler.step(perf_indicator)\n",
        "\n",
        "\n",
        "model = None\n",
        "criterion = None\n",
        "optimizer = None\n",
        "epoch_begin = 0\n",
        "log_writer = None\n",
        "\n",
        "def pill_classifier(args):\n",
        "    global model, criterion, optimizer, epoch_begin, log_writer\n",
        "    if args.dataset_valid != None:\n",
        "        dataloader_valid = DataLoader(args.dataset_valid, batch_size=args.batch_size, shuffle= False, num_workers=args.num_workers)\n",
        "    else:\n",
        "        dataloader_valid = None\n",
        "\n",
        "    if args.run_phase == 'train' and args.dataset_train != None:\n",
        "        dataloader_train = DataLoader(args.dataset_train, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
        "    else:\n",
        "        dataloader_train = None\n",
        "\n",
        "    if model == None :\n",
        "        log_writer = SummaryWriter(args.dir_log)\n",
        "        if args.cuda == False or torch.cuda.device_count() == 0  :\n",
        "            args.gpu = None\n",
        "        else:\n",
        "            args.gpu = 0\n",
        "\n",
        "        args.rank = args.gpu\n",
        "\n",
        "        cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cudnn.enabled = True\n",
        "\n",
        "        model = get_pill_model(args)\n",
        "\n",
        "        # define loss function (criterion) and optimizer\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        if args.cuda:\n",
        "            criterion = criterion.cuda()\n",
        "        optimizer = get_optimizer(args,model)\n",
        "        epoch_begin, dict_checkpoint, success = model_load(args, model, optimizer)\n",
        "\n",
        "    run_model(args, model, dataloader_train, dataloader_valid, None, None,  criterion,optimizer, epoch_begin, log_writer )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # job = 'hrnet_w64'\n",
        "    job = 'resnet152'\n",
        "    args = get_cli_args(job=job, run_phase='test', aug_level=0, dataclass='0')\n",
        "\n",
        "    print(f'model_path_in is {args.model_path_in}')\n",
        "\n",
        "    end = time.time()\n",
        "    if args.run_phase == 'train'  :\n",
        "        args.dataset_train = Dataset_Pill(args, args.json_pill_class_list,  transform=transform_normalize, run_phase='train')\n",
        "        print(f'train dataset was loaded')\n",
        "\n",
        "    args.dataset_valid = Dataset_Pill(args, args.json_pill_class_list, transform=transform_normalize, run_phase='test' if args.run_phase == 'test' else 'valid')\n",
        "    print(f'valid dataset was loaded')\n",
        "\n",
        "\n",
        "    print(f'dataset loading time is {time.time() - end}')\n",
        "\n",
        "    pill_classifier(args)\n",
        "    print('job done')"
      ],
      "metadata": {
        "id": "C7Yeo6-VM5us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**utils.py**"
      ],
      "metadata": {
        "id": "5NTh7yaEM-E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs, json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import torch.optim as optim\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import logging\n",
        "\n",
        "\n",
        "def inverse_vgg_preprocess(image):\n",
        "    means = [0.485, 0.456, 0.406]\n",
        "    stds = [0.229, 0.224, 0.225]\n",
        "    image = image.copy().transpose((1, 2, 0))  # 원본 손상 방지.\n",
        "\n",
        "    for i in range(3):\n",
        "        image[:, :, i] = image[:, :, i] * stds[i]\n",
        "        image[:, :, i] = image[:, :, i] + means[i]\n",
        "    image = image[:, :, ::-1]\n",
        "    image = image * 255\n",
        "\n",
        "    image[image > 255.] = 255.\n",
        "    image[image < 0.] = 0.\n",
        "    image = image.astype(np.uint8)\n",
        "\n",
        "    return image\n",
        "\n",
        "##########################################################################\n",
        "def save_dict_to_json(dict_save, filejson, mode='w'):\n",
        "    with codecs.open(filejson, mode, encoding='utf-8') as f:\n",
        "        json.dump(dict_save, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "\n",
        "def read_dict_from_json(filejson):\n",
        "    if not os.path.isfile(filejson) :\n",
        "        return None\n",
        "    with codecs.open(filejson, 'r', encoding='utf-8') as f:\n",
        "        obj = json.load(f)\n",
        "        return obj\n",
        "\n",
        "def open_opencv_file(filename):\n",
        "    img_array = np.fromfile(filename, np.uint8)\n",
        "    image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "    return image\n",
        "\n",
        "def save_opencv_file(image, filename):\n",
        "    result, encoded_img = cv2.imencode('.jpg', image)\n",
        "    if result:\n",
        "        with open(filename, mode='w+b') as f:\n",
        "            encoded_img.tofile(f)\n",
        "            return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def show_cvimage(image):\n",
        "    cv2.imshow('a', image)\n",
        "    cv2.waitKey()                   # wait을 해야, 이미지가 나온다. PIL은  im.show()으로 바로 나온다.\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "def show_tensor3(inp, cmap=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp, cmap)\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_tensor3(inp, filename):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    matplotlib.image.imsave(filename, inp)\n",
        "\n",
        "\n",
        "\n",
        "def model_save(model_path, epoch, model, optimizer, rank=0) :\n",
        "    if rank == 0 :\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict() if optimizer != None else 0 ,\n",
        "        }, model_path)\n",
        "        print(f'model was saved to {model_path}')\n",
        "\n",
        "def model_load(args, model, optimizer, rank=0) :\n",
        "    epoch_begin = 0\n",
        "    state_model = None\n",
        "    state_optimizer = None\n",
        "    if not os.path.isfile(args.model_path_in):\n",
        "        print(f\"-------------------------------------------------->>>>>>>>>>>>> model_path doesn't exist:{args.model_path_in}\")\n",
        "        return  epoch_begin, None, False      # None check point to indicate a fail\n",
        "\n",
        "    if args.verbose == True: print(f\"model_path will be loaded from:{args.model_path_in}\")\n",
        "\n",
        "    dict_checkpoint = torch.load(args.model_path_in, map_location='cpu')\n",
        "\n",
        "    epoch_begin = dict_checkpoint.get('epoch', -1 ) + 1\n",
        "    if rank == 0 :\n",
        "        try:\n",
        "            state_model = dict_checkpoint.get('model', None )\n",
        "            if state_model != None :\n",
        "                if not hasattr(model, 'module') and ('module' in list(state_model.keys())[0] ) :           # model_path은  module 을 포함하고 있다고 가정한다.\n",
        "                    state_model = OrderedDict([ ( k[7:], v ) if 'module' in k else (k,v ) for k,v in state_model.items()])\n",
        "                    model.load_state_dict(state_model)\n",
        "                    print(f'model was loaded from module state')\n",
        "                elif hasattr(model, 'module') and (not 'module' in list(state_model.keys())[0] ) :\n",
        "                    state_model = OrderedDict([('module.' + k, v)  for k, v in state_model.items()])\n",
        "                    model.load_state_dict(state_model)\n",
        "                    print(f'module.model was loaded from normal state')\n",
        "                else:\n",
        "                    model.load_state_dict(state_model)\n",
        "                    print(f'model was loaded from state')\n",
        "            else:\n",
        "                print(f'No model checkpoint in file')\n",
        "\n",
        "        except Exception as e :\n",
        "            print(f'Fail to loading model: {e}')\n",
        "            return epoch_begin, dict_checkpoint, False\n",
        "\n",
        "        if optimizer != None and args.run_phase == 'train':\n",
        "            try:\n",
        "                state_optimizer = dict_checkpoint.get('optimizer', None )\n",
        "                if state_optimizer != None:\n",
        "                    optimizer.load_state_dict(state_optimizer)\n",
        "                    print(f'optimizer was loaded from state')\n",
        "                else:\n",
        "                    print(f'No optimizer checkpoint in file')\n",
        "            except Exception as e :\n",
        "                print(f'Fail to loading optimizer: {e}')\n",
        "                return epoch_begin, dict_checkpoint, False\n",
        "    success = True if state_model != None and state_optimizer != None else False\n",
        "    return epoch_begin, dict_checkpoint, success\n",
        "\n",
        "\n",
        "def convert_pil_to_cv2(pil_image):\n",
        "    pil_image = pil_image.convert('RGB')\n",
        "    open_cv_image = np.array(pil_image)\n",
        "    # Convert RGB to BGR\n",
        "    open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "    return open_cv_image\n",
        "\n",
        "def convert_cv2_to_pil(cv_image):\n",
        "    pil_img = Image.fromarray(cv_image)\n",
        "    return pil_img\n",
        "\n",
        "def save_img_paf_heat(path, img_temp, paf_temp, heatmap_temp, args ):\n",
        "    path = Path(path)\n",
        "\n",
        "    if path.parts[-2].isdigit() :\n",
        "        dir_paf = os.path.join(args.dir_review_paf_train, path.parts[-2] )\n",
        "        dir_heat = os.path.join(args.dir_review_heat_train, path.parts[-2])\n",
        "        dir_img = os.path.join(args.dir_review_img_train, path.parts[-2])\n",
        "    else:\n",
        "        dir_paf = args.dir_output\n",
        "        dir_heat = args.dir_output\n",
        "        dir_img = args.dir_output\n",
        "\n",
        "    os.makedirs(dir_paf, exist_ok=True)\n",
        "    os.makedirs(dir_heat, exist_ok=True)\n",
        "    os.makedirs(dir_img, exist_ok=True)\n",
        "\n",
        "    file_base = path.name.split('.')[0]\n",
        "    filename_img = os.path.join(dir_img, file_base + '_base.jpg')\n",
        "    filename_paf = os.path.join(dir_paf, file_base + '_paf.jpg')\n",
        "    filename_heat = os.path.join(dir_heat, file_base + '_heat.jpg')\n",
        "\n",
        "    save_opencv_file(inverse_vgg_preprocess(img_temp), filename_img)\n",
        "    save_opencv_file(inverse_vgg_preprocess(paf_temp), filename_paf)\n",
        "    save_opencv_file(inverse_vgg_preprocess(heatmap_temp), filename_heat)\n",
        "\n",
        "def open_pil_as_stack_gray_np(filename):\n",
        "    np_pil = np.array(Image.open(filename).convert('L'))\n",
        "    np_pil = np.dstack([np_pil,np_pil,np_pil])\n",
        "    return np_pil\n",
        "\n",
        "def open_pil_as_stack_color_np(filename):\n",
        "    np_pil = np.array(Image.open(filename))\n",
        "    return np_pil\n",
        "\n",
        "def save_np_pil_file(np_image, filename):\n",
        "    image_pil = Image.fromarray(np_image)\n",
        "    image_pil.save(filename)\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)      #  maxk, dim=1, largest, sorted -> ( value tensor, index longTensor )\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "\n",
        "def saveimage(sub, dir_digit, basename):\n",
        "    filename_jpg = os.path.join(dir_digit, basename + '.jpg')\n",
        "    sub.save(filename_jpg)\n",
        "\n",
        "\n",
        "def extractDigit_saveto(file_json, file_bmp, list_dir_digit=None):\n",
        "    dict_bmp_info = read_dict_from_json(file_json)\n",
        "\n",
        "    digitFractNo = int(dict_bmp_info['digitFractNo'])\n",
        "    digitAllNo = int(dict_bmp_info['digitAllNo'])\n",
        "    dataValue = int(dict_bmp_info['dataValue'] * 10 ** digitFractNo)\n",
        "    digitRect = dict_bmp_info['digitRect']\n",
        "    str_dataValue = f'{dataValue:0{digitAllNo}}'\n",
        "    str_igmsGaugeDataId = dict_bmp_info['igmsGaugeDataId']\n",
        "\n",
        "    if len(str_dataValue) != digitAllNo:\n",
        "        if len(str_igmsGaugeDataId) == digitAllNo:\n",
        "            str_dataValue = str_igmsGaugeDataId\n",
        "        else:\n",
        "            print(f'{file_json}')\n",
        "            raise Exception(\"improper data format\")\n",
        "\n",
        "\n",
        "    list_digitRect = digitRect.split('|')[1:digitAllNo+1]\n",
        "    list_digitRect = [aa.split(',') for aa in list_digitRect]\n",
        "    list_digitRect = [[int(a), int(b), int(c), int(d)] for a, b, c, d in list_digitRect]\n",
        "\n",
        "    img = Image.open(file_bmp)\n",
        "    if img == None:\n",
        "        print(f\"Can't read a image file :{file_bmp}\")\n",
        "        return\n",
        "\n",
        "    list_image = []\n",
        "    for index in range(digitAllNo):\n",
        "        x, y, width, height = list_digitRect[index]\n",
        "        sub = img.crop((x, y, x + width, y + height))\n",
        "        if list_dir_digit != None :\n",
        "            saveimage(sub, list_dir_digit[int(str_dataValue[index])], os.path.basename(file_json).split('.')[0] + f'_{index}{str_dataValue[index]}')\n",
        "        else:\n",
        "            list_image.append(sub.convert('RGB'))\n",
        "\n",
        "    if list_dir_digit == None :\n",
        "        return list_image, [int(aa) for aa in str_dataValue], dict_bmp_info\n",
        "\n",
        "def get_Image_Value_List_from_json(file_json):\n",
        "    list_image, list_value, dict_json_info = extractDigit_saveto(file_json, os.path.splitext(file_json)[0] + '.bmp')\n",
        "    list_cv_label_path = [(list_image[i], list_value[i], file_json) for i in range(len(list_image))]\n",
        "    return list_cv_label_path\n",
        "\n",
        "transform_normalize = transforms.Compose([\n",
        "                                 transforms.ToTensor(),\n",
        "                                 transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                                      std=[0.229, 0.224, 0.225])\n",
        "                             ])\n",
        "\n",
        "transform_classifier = transforms.Compose([transforms.Resize((224, 224))\n",
        "                                         , transforms.ToTensor()\n",
        "                                         , transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "transfrom_paf = transforms.Compose([transforms.Resize((368, 368))\n",
        "                                         , transforms.ToTensor()\n",
        "                                         , transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "                                      ])\n",
        "\n",
        "class Dataset_valid(Dataset):\n",
        "    def __init__(self, file_json, transform):\n",
        "        if os.path.isfile(file_json) and file_json.split('.')[-1] == 'json':\n",
        "            self.list_cv_label_path = get_Image_Value_List_from_json(file_json)\n",
        "        elif os.path.isdir(file_json):\n",
        "            self.list_cv_label_path = [(Image.open(aa).convert(\"RGB\"), int(str(Path(aa).parts[-2])), aa) for aa in glob(file_json + r'/**/*.jpg')]\n",
        "        self.transform = transform\n",
        "        self.file_json = file_json\n",
        "\n",
        "    def __len__(self):\n",
        "        # return size of dataset\n",
        "        return len(self.list_cv_label_path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label, path = self.list_cv_label_path[idx]\n",
        "        if self.transform != None:\n",
        "            image = self.transform(image)\n",
        "        return image, (label, path)\n",
        "\n",
        "def get_optimizer(args, model):\n",
        "    optimizer = None\n",
        "    if args.optimizer == 'sgd':\n",
        "        optimizer = optim.SGD(\n",
        "            filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=args.lr,\n",
        "            momentum=args.momentum,\n",
        "            weight_decay=args.wd,\n",
        "            nesterov=args.nesterov\n",
        "        )\n",
        "        if args.verbose == True: print(f'optimizer was selected as type:sgd')\n",
        "    elif args.optimizer == 'adam':\n",
        "        optimizer = optim.Adam( filter(lambda p: p.requires_grad, model.parameters()), lr=args.lr)\n",
        "        if args.verbose == True: print(f'optimizer was selected as type:adam')\n",
        "    elif args.optimizer == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(\n",
        "            filter(lambda p: p.requires_grad, model.parameters()),\n",
        "            lr=args.lr,\n",
        "            momentum=args.momentum,\n",
        "            weight_decay=args.wd,\n",
        "        )\n",
        "        if args.verbose == True: print(f'optimizer was selected as type:rmsprop')\n",
        "    return optimizer\n",
        "\n",
        "def adjust_learning_rate(args, optimizer, epoch):\n",
        "    assert hasattr(args, 'lr_schedule'), \"args doesn't have lr schedule\"\n",
        "    assert hasattr(args, 'lr_gamma'), \"args doesn't have lr gamma\"\n",
        "    assert hasattr(args, 'lr'), \"args doesn't have lr\"\n",
        "\n",
        "    if epoch in args.lr_schedule:\n",
        "        args.lr *= args.lr_gamma\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = args.lr\n",
        "\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"  val을 계속 누적하고,  평균을 구함.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "\n",
        "    @property\n",
        "    def avg(self):\n",
        "        return self.sum / self.count\n",
        "\n",
        "    @property\n",
        "    def val(self):\n",
        "        return self.sum\n",
        "\n",
        "def create_logging(file_log):\n",
        "    path_file_log = Path(file_log)\n",
        "    path_dir_log = path_file_log.parent\n",
        "    path_dir_log.mkdir(exist_ok=True)\n",
        "\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    formatter_stream = logging.Formatter(u'%(message)s')\n",
        "    streamingHandler = logging.StreamHandler()\n",
        "    streamingHandler.setFormatter(formatter_stream)\n",
        "\n",
        "    formatter_file = logging.Formatter(u'%(asctime)s [%(levelname)8s] %(message)s')\n",
        "    file_handler = logging.FileHandler(file_log)\n",
        "    file_handler.setFormatter(formatter_file)\n",
        "\n",
        "    logger.addHandler(streamingHandler)\n",
        "    logger.addHandler(file_handler)\n",
        "\n",
        "    return logger\n",
        "\n"
      ],
      "metadata": {
        "id": "4TRPtBR5NAZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}